{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb0f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171d84b",
   "metadata": {},
   "source": [
    "# ğŸ”„ Â¿QuÃ© es un Pipeline de Datos en Python?\n",
    "\n",
    "Imagina que tienes que preparar una receta en la cocina. Para que el plato quede perfecto, necesitas seguir varios pasos: lavar los ingredientes, picarlos, cocinarlos, sazonar, etc. Un **pipeline de datos** es algo muy parecido, pero en lugar de preparar comida, preparamos datos ğŸ¥—â¡ğŸ“Š.\n",
    "\n",
    "Un *pipeline* (o \"tuberÃ­a\") es una secuencia de pasos por donde pasan los datos para ser transformados. Cada paso hace algo con los datos: puede limpiarlos, convertirlos, analizarlos o visualizarlos.\n",
    "\n",
    "## âœ… Â¿Para quÃ© sirve un pipeline?\n",
    "\n",
    "- **Organizar** el trabajo con los datos.\n",
    "- **Repetir procesos fÃ¡cilmente** sin escribir todo desde cero.\n",
    "- **Evitar errores**, ya que los pasos estÃ¡n bien definidos.\n",
    "- Es muy Ãºtil cuando se trabaja con muchos datos o en equipo.\n",
    "\n",
    "## ğŸ‘€ Ejemplo de la vida real\n",
    "\n",
    "Supongamos que tienes una lista de personas que se inscribieron a un curso, pero los datos estÃ¡n algo desordenados. Un pipeline podrÃ­a:\n",
    "1. Limpiar los nombres (quitar espacios o errores de escritura).\n",
    "2. Eliminar registros vacÃ­os o repetidos.\n",
    "3. Calcular cuÃ¡ntos estudiantes hay por ciudad.\n",
    "4. Mostrar los resultados en una tabla ordenada.\n",
    "\n",
    "Al automatizar estos pasos con un pipeline, puedes repetir el proceso cada vez que lleguen nuevos datos sin hacerlo manualmente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec2bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de personas por ciudad:\n",
      "Ciudad\n",
      "BogotÃ¡      1\n",
      "MedellÃ­n    1\n",
      "Cali        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Creamos un \"DataFrame\" con datos simulados\n",
    "data = pd.DataFrame({\n",
    "    'Nombre': [' Ana ', 'Luis', 'ana', None, 'CARLOS', 'Luis'],\n",
    "    'Ciudad': ['BogotÃ¡', 'MedellÃ­n', 'BogotÃ¡', 'Cali', 'Cali', 'MedellÃ­n']\n",
    "})\n",
    "\n",
    "# 2. Pipeline de procesamiento de datos paso a paso\n",
    "\n",
    "# Paso 1: Eliminar espacios en los nombres y ponerlos en minÃºscula\n",
    "data['Nombre'] = data['Nombre'].str.strip().str.lower()\n",
    "\n",
    "# Paso 2: Eliminar filas con datos faltantes\n",
    "data = data.dropna()\n",
    "\n",
    "# Paso 3: Eliminar duplicados\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Paso 4: Contar cuÃ¡ntas personas hay por ciudad\n",
    "conteo_ciudades = data['Ciudad'].value_counts()\n",
    "\n",
    "# Paso 5: Mostrar el resultado\n",
    "print(\"Cantidad de personas por ciudad:\")\n",
    "print(conteo_ciudades)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed6850d",
   "metadata": {},
   "source": [
    "# ğŸ› ï¸ Pipeline de Datos (ETL) con PostgreSQL y Python\n",
    "\n",
    "Un pipeline ETL (Extract, Transform, Load) es como una fÃ¡brica de datos. Cada letra representa una fase:\n",
    "\n",
    "- **Extract (Extraer)**: Traemos datos desde una fuente, por ejemplo una base de datos.\n",
    "- **Transform (Transformar)**: Limpiamos y organizamos los datos para que tengan sentido.\n",
    "- **Load (Cargar)**: Guardamos los datos procesados en un nuevo lugar, como otra tabla o archivo, listos para anÃ¡lisis.\n",
    "\n",
    "## ğŸ§ƒ Caso de la vida real\n",
    "\n",
    "Imagina que trabajas en una empresa que guarda informaciÃ³n de ventas en una base de datos PostgreSQL. Pero esos datos estÃ¡n algo sucios: hay valores vacÃ­os, nombres mal escritos y fechas en distintos formatos.\n",
    "\n",
    "Queremos construir un pipeline que:\n",
    "\n",
    "1. **Extraiga** los datos desde PostgreSQL.\n",
    "2. **Limpie** errores comunes (como espacios extra o valores faltantes).\n",
    "3. **Cargue** los datos limpios en una nueva tabla que luego se conectarÃ¡ a una herramienta de visualizaciÃ³n como **Looker Studio**, para crear dashboards.\n",
    "\n",
    "Este proceso permite automatizar el flujo de datos desde su origen hasta la visualizaciÃ³n, ahorrando tiempo y evitando errores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d9099",
   "metadata": {},
   "source": [
    "# ğŸ“Š Â¿QuÃ© es Looker Studio?\n",
    "\n",
    "**Looker Studio** (antes llamado Google Data Studio) es una herramienta gratuita de Google que permite crear **dashboards interactivos** y **reportes visuales** usando datos de diferentes fuentes.\n",
    "\n",
    "Es como hacer presentaciones, pero con datos vivos: si cambian los datos en la fuente, Â¡se actualiza el grÃ¡fico automÃ¡ticamente! ğŸ”„\n",
    "\n",
    "## ğŸ§© Â¿QuÃ© puedo hacer con Looker Studio?\n",
    "\n",
    "- Mostrar **grÃ¡ficos, tablas y mapas** con datos.\n",
    "- Conectar a fuentes como: hojas de cÃ¡lculo, bases de datos, Google Analytics, BigQuery o archivos CSV.\n",
    "- Compartir dashboards con otras personas, como si fueran documentos de Google.\n",
    "- Filtrar y explorar los datos fÃ¡cilmente (sin necesidad de saber programar).\n",
    "\n",
    "## ğŸŒ Caso de uso real\n",
    "\n",
    "SupÃ³n que hiciste un anÃ¡lisis en Python de las ventas por ciudad de una empresa. Los datos limpios quedaron guardados en una tabla de PostgreSQL llamada `ventas_limpias`.\n",
    "\n",
    "Con **Looker Studio**, puedes:\n",
    "\n",
    "1. Conectarte a esa tabla directamente.\n",
    "2. Crear un grÃ¡fico de barras con las ventas por ciudad.\n",
    "3. Compartir el reporte con tu equipo para tomar decisiones basadas en datos.\n",
    "\n",
    "Todo esto sin escribir ni una lÃ­nea de cÃ³digo.\n",
    "\n",
    "## ğŸª„ Ventajas para quienes no programan\n",
    "\n",
    "- No necesitas saber Python ni SQL para usar Looker Studio.\n",
    "- Es muy visual e intuitivo.\n",
    "- Puedes construir reportes profesionales en poco tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”Œ Â¿CÃ³mo conecto Looker Studio a una base de datos?\n",
    "\n",
    "1. Entra a: [https://lookerstudio.google.com](https://lookerstudio.google.com)\n",
    "2. Crea un nuevo reporte.\n",
    "3. Haz clic en \"**AÃ±adir datos**\".\n",
    "4. Elige la fuente: por ejemplo, **PostgreSQL**.\n",
    "5. Escribe los datos de conexiÃ³n: host, usuario, contraseÃ±a, nombre de la base de datos y tabla (como `ventas_limpias`).\n",
    "6. Haz clic en **Conectar**, y Â¡listo!\n",
    "\n",
    "Ahora puedes crear grÃ¡ficos con esos datos como si fuera una hoja de cÃ¡lculo.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Â¿QuÃ© puedes visualizar?\n",
    "\n",
    "- Tendencias de ventas por mes ğŸ“ˆ\n",
    "- ComparaciÃ³n de productos mÃ¡s vendidos ğŸ¥‡\n",
    "- Mapa de ventas por ciudad ğŸ—ºï¸\n",
    "- Tablas con filtros interactivos ğŸ”\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline_etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
