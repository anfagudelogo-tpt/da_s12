{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beef6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    conectar_postgresql,\n",
    "    ejecutar_query,\n",
    "    cargar_dataframe_postgresql,\n",
    "    read_json_file,\n",
    "    limpieza_general\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ae659",
   "metadata": {},
   "source": [
    "# üöÄ Ejercicio: Construcci√≥n de un Pipeline de Datos con PostgreSQL y Looker Studio\n",
    "\n",
    "En este ejercicio vas a construir un pipeline de datos completo que conecte Python con PostgreSQL y Looker Studio. El objetivo es automatizar el flujo de datos: desde su extracci√≥n, limpieza y almacenamiento, hasta su visualizaci√≥n en un dashboard interactivo.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Objetivo\n",
    "\n",
    "1. Leer las credenciales necesarias para conectarse a una base de datos PostgreSQL.\n",
    "2. Establecer la conexi√≥n usando Python y la librer√≠a `SQLAlchemy`.\n",
    "3. Ejecutar una consulta SQL que obtenga datos desde una tabla de la base de datos.\n",
    "4. Realizar una limpieza b√°sica de los datos obtenidos.\n",
    "5. Guardar el DataFrame limpio como una nueva tabla en PostgreSQL.\n",
    "6. Crear un nuevo proyecto en **Looker Studio**.\n",
    "7. Conectar Looker Studio a la nueva tabla de la base de datos.\n",
    "8. Crear visualizaciones gr√°ficas interactivas con los datos procesados.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Instrucciones\n",
    "\n",
    "### 1. üìÇ Leer credenciales desde un archivo `.env` o diccionario\n",
    "- Incluye los siguientes datos:\n",
    "  - `host`\n",
    "  - `dbname`\n",
    "  - `user`\n",
    "  - `password`\n",
    "\n",
    "### 2. üß± Conectarte a la base de datos PostgreSQL\n",
    "- Usa `SQLAlchemy` o `psycopg2` para conectarte.\n",
    "\n",
    "### 3. üì§ Ejecutar un `SELECT` para extraer los datos de una tabla (por ejemplo: `ventas_originales`)\n",
    "\n",
    "### 4. üßº Limpieza de datos\n",
    "- Elimina filas con valores vac√≠os (`NaN`).\n",
    "- Corrige nombres o formatos si es necesario (por ejemplo, columnas de texto o fechas).\n",
    "- Elimina duplicados.\n",
    "\n",
    "### 5. üßæ Guardar los datos limpios\n",
    "- Crea una nueva tabla en la base de datos, por ejemplo: `ventas_limpias`.\n",
    "\n",
    "### 6. üßë‚Äçüíª Crear un proyecto en Looker Studio\n",
    "- Ve a [https://lookerstudio.google.com](https://lookerstudio.google.com).\n",
    "- Crea un nuevo reporte.\n",
    "- Agrega una fuente de datos tipo **PostgreSQL** con las mismas credenciales.\n",
    "- Selecciona la tabla `ventas_limpias`.\n",
    "\n",
    "### 7. üìà Crear visualizaciones\n",
    "- Agrega los siguientes elementos al dashboard:\n",
    "  - Gr√°fico de barras: ventas por ciudad.\n",
    "  - L√≠nea de tiempo: evoluci√≥n de ventas por fecha.\n",
    "  - Tabla con totales y filtros por regi√≥n o cliente.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Resultado esperado\n",
    "\n",
    "Al finalizar este ejercicio deber√≠as tener:\n",
    "\n",
    "- Un c√≥digo en Python que ejecuta un pipeline ETL con PostgreSQL.\n",
    "- Una nueva tabla limpia en la base de datos.\n",
    "- Un dashboard en Looker Studio conectado a esa tabla, con gr√°ficos din√°micos e interactivos.\n",
    "\n",
    "---\n",
    "\n",
    "üí° *Este flujo es el que muchas empresas usan en el mundo real para tomar decisiones basadas en datos.* ¬°T√∫ tambi√©n puedes hacerlo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b65a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = read_json_file('credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb35ee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conexi√≥n exitosa a PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "conn = conectar_postgresql(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce89c480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Consulta ejecutada exitosamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andres Agudelo\\Documents\\da_s12\\class_1\\utils.py:51: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "df = ejecutar_query(\n",
    "    conn,\n",
    "    'select * from datos_transaccionales'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "547e0718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>sale_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>Home</td>\n",
       "      <td>229</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>575</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>864</td>\n",
       "      <td>2024-01-03 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>Food</td>\n",
       "      <td>745</td>\n",
       "      <td>2024-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>234</td>\n",
       "      <td>2024-01-05 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sale_id  customer_id     category  amount            sale_date\n",
       "0        1          106         Home     229  2024-01-01 00:00:00\n",
       "1        2          103      Clothes     575  2024-01-02 00:00:00\n",
       "2        3          107  Electronics     864  2024-01-03 00:00:00\n",
       "3        4          104         Food     745  2024-01-04 00:00:00\n",
       "4        5          106       Beauty     234  2024-01-05 00:00:00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e4484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Columna 'sale_date' convertida a fecha.\n",
      "\n",
      "üìä Tipos de datos:\n",
      "sale_id                 int64\n",
      "customer_id             int64\n",
      "category               object\n",
      "amount                  int64\n",
      "sale_date      datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "üîç Valores nulos por columna:\n",
      "sale_id        0\n",
      "customer_id    0\n",
      "category       0\n",
      "amount         0\n",
      "sale_date      0\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Limpieza general completada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andres Agudelo\\Documents\\da_s12\\class_1\\utils.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors=\"raise\")\n"
     ]
    }
   ],
   "source": [
    "clean_df = limpieza_general(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabla 'datos_transaccionales_limpios' creada o reemplazada exitosamente.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cargar_dataframe_postgresql(\n",
    "    clean_df,\n",
    "    'datos_transaccionales_limpios',\n",
    "    credentials\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline_etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
